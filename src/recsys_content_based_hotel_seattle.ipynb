{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import re\n",
    "import random\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import cufflinks\n",
    "\n",
    "pd.options.display.max_columns = 30\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "from plotly.offline import iplot\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='solar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'https://docs.google.com/spreadsheets/d/1HE6vUktQd7p0sYXmk87l6Rc4MQyUkJhEHBmsHJ9GyTY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spreadsheet(link):\n",
    "  \n",
    "    r = requests.get(link + '/export?format=csv&id')\n",
    "    return pd.read_csv(BytesIO(r.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hilton Garden Seattle Downtown</td>\n",
       "      <td>1821 Boren Avenue, Seattle Washington 98101 USA</td>\n",
       "      <td>Located on the southern tip of Lake Union, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sheraton Grand Seattle</td>\n",
       "      <td>1400 6th Avenue, Seattle, Washington 98101 USA</td>\n",
       "      <td>Located in the city's vibrant core, the Sherat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crowne Plaza Seattle Downtown</td>\n",
       "      <td>1113 6th Ave, Seattle, WA 98101</td>\n",
       "      <td>Located in the heart of downtown Seattle, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kimpton Hotel Monaco Seattle</td>\n",
       "      <td>1101 4th Ave, Seattle, WA98101</td>\n",
       "      <td>What?s near our hotel downtown Seattle locatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Westin Seattle</td>\n",
       "      <td>1900 5th Avenue, Seattle, Washington 98101 USA</td>\n",
       "      <td>Situated amid incredible shopping and iconic a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name  \\\n",
       "0  Hilton Garden Seattle Downtown   \n",
       "1          Sheraton Grand Seattle   \n",
       "2   Crowne Plaza Seattle Downtown   \n",
       "3    Kimpton Hotel Monaco Seattle   \n",
       "4              The Westin Seattle   \n",
       "\n",
       "                                           address  \\\n",
       "0  1821 Boren Avenue, Seattle Washington 98101 USA   \n",
       "1   1400 6th Avenue, Seattle, Washington 98101 USA   \n",
       "2                  1113 6th Ave, Seattle, WA 98101   \n",
       "3                   1101 4th Ave, Seattle, WA98101   \n",
       "4   1900 5th Avenue, Seattle, Washington 98101 USA   \n",
       "\n",
       "                                                desc  \n",
       "0  Located on the southern tip of Lake Union, the...  \n",
       "1  Located in the city's vibrant core, the Sherat...  \n",
       "2  Located in the heart of downtown Seattle, the ...  \n",
       "3  What?s near our hotel downtown Seattle locatio...  \n",
       "4  Situated amid incredible shopping and iconic a...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_spreadsheet(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_description(index):\n",
    "    example = df[df.index == index][['desc', 'name']].values[0]\n",
    "    if len(example) > 0:\n",
    "        print(example[0])\n",
    "        print('Name:', example[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soak up the vibrant scene in the Living Room Bar and get in the mix with our live music and DJ series before heading to a memorable dinner at TRACE. Offering inspired seasonal fare in an award-winning atmosphere, it's a not-to-be-missed culinary experience in downtown Seattle. Work it all off the next morning at FIT®, our state-of-the-art fitness center before wandering out to explore many of the area's nearby attractions, including Pike Place Market, Pioneer Square and the Seattle Art Museum. As always, we've got you covered during your time at W Seattle with our signature Whatever/Whenever® service - your wish is truly our command.\n",
      "Name: W Seattle\n"
     ]
    }
   ],
   "source": [
    "print_description(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On a budget in Seattle or looking for something different? The historic charm and \"home away from home\" atmosphere of The Baroness will be sure to make you feel like one of the family. Conveniently located on First Hill, we are proud to be part of the Virginia Mason Hospital campus and only minutes from Harborview Medical Center and Swedish Hospital. The Baroness Hotel is a great option for short or long term medical, patient or family stays. Whether you are visiting the area's world-class medical facilities or on a budget vacation, our goal is to ensure a wonderful stay. Guest Amenities: Complimentary Internet access, Two twin, one or two queen studios with mini fridge and microwave, Two twin or one queen suites with full kitchens, Laundry facilities available, Flat screen cable television with HBO, Complimentary local calls, Ice and vending machines located in the lobby, Coffee maker and hairdryers in all guestrooms, Room service available seven days a week from the Rhododendron Cafe, Limited wheelchair accessibility, Guest library and business center, Printing & fax services available, 100% non-smoking and pet free, Rooms are not air conditioned - fans are available, Self-parking available at Virginia Mason hospital for a fee.\n",
      "Name: The Baroness Hotel\n"
     ]
    }
   ],
   "source": [
    "print_description(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "desc\n",
       "on           129\n",
       "downtown     133\n",
       "are          136\n",
       "center       151\n",
       "or           161\n",
       "your         186\n",
       "for          216\n",
       "from         224\n",
       "at           231\n",
       "is           271\n",
       "with         280\n",
       "hotel        295\n",
       "you          304\n",
       "our          359\n",
       "in           449\n",
       "to           471\n",
       "seattle      533\n",
       "of           536\n",
       "and         1062\n",
       "the         1258\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDA\n",
    "# Token (vocabulary) Frequency Distribution Before Removing Stop Words\n",
    "\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "common_words = get_top_n_words(df['desc'], 20)\n",
    "df1 = pd.DataFrame(common_words, columns = ['desc' , 'count'])\n",
    "df1.groupby('desc').sum()['count'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "desc\n",
       "breakfast     68\n",
       "room          77\n",
       "city          79\n",
       "just          82\n",
       "business      87\n",
       "inn           89\n",
       "pike          90\n",
       "enjoy         93\n",
       "market        97\n",
       "space         97\n",
       "airport       99\n",
       "place        102\n",
       "stay         105\n",
       "rooms        106\n",
       "located      108\n",
       "free         123\n",
       "downtown     133\n",
       "center       151\n",
       "hotel        295\n",
       "seattle      533\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Token (vocabulary) Frequency Distribution After Removing Stop Words\n",
    "\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer(stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "common_words = get_top_n_words(df['desc'], 20)\n",
    "df2 = pd.DataFrame(common_words, columns = ['desc' , 'count'])\n",
    "df2.groupby('desc').sum()['count'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "desc\n",
       "in the              147\n",
       "of the              133\n",
       "pike place           86\n",
       "place market         85\n",
       "to the               81\n",
       "downtown seattle     79\n",
       "from the             79\n",
       "and the              72\n",
       "space needle         68\n",
       "at the               67\n",
       "in seattle           60\n",
       "the seattle          57\n",
       "our hotel            54\n",
       "hotel is             49\n",
       "of our               45\n",
       "the city             45\n",
       "of seattle           44\n",
       "one of               42\n",
       "you ll               41\n",
       "the space            40\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bigrams Frequency Distribution Before Removing Stop Words\n",
    "\n",
    "def get_top_n_bigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "common_words = get_top_n_bigram(df['desc'], 20)\n",
    "df3 = pd.DataFrame(common_words, columns = ['desc' , 'count'])\n",
    "df3.groupby('desc').sum()['count'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "desc\n",
       "pike place               86\n",
       "place market             85\n",
       "downtown seattle         80\n",
       "space needle             68\n",
       "wi fi                    37\n",
       "guest rooms              34\n",
       "seattle hotel            33\n",
       "pacific northwest        33\n",
       "fitness center           32\n",
       "hotel seattle            30\n",
       "lake union               30\n",
       "24 hour                  28\n",
       "international airport    27\n",
       "business center          27\n",
       "seattle airport          26\n",
       "high speed               25\n",
       "seattle tacoma           25\n",
       "university washington    24\n",
       "seattle center           24\n",
       "convention center        21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bigrams Frequency Distribution After Removing Stop Words\n",
    "\n",
    "def get_top_n_bigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(2, 2), stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "common_words = get_top_n_bigram(df['desc'], 20)\n",
    "df4 = pd.DataFrame(common_words, columns = ['desc' , 'count'])\n",
    "df4.groupby('desc').sum()['count'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "desc\n",
       "pike place market               85\n",
       "the space needle                39\n",
       "the heart of                    33\n",
       "in the heart                    28\n",
       "located in the                  26\n",
       "place market and                24\n",
       "the pacific northwest           23\n",
       "university of washington        23\n",
       "one of the                      22\n",
       "tacoma international airport    21\n",
       "seattle tacoma international    21\n",
       "easy access to                  20\n",
       "free wi fi                      19\n",
       "of the city                     17\n",
       "washington state convention     17\n",
       "our hotel is                    16\n",
       "of downtown seattle             16\n",
       "seattle art museum              16\n",
       "state convention center         15\n",
       "hotel in seattle                15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trigrams Frequency Distribution Before Removing Stop Words\n",
    "\n",
    "def get_top_n_trigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(3, 3)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "common_words = get_top_n_trigram(df['desc'], 20)\n",
    "df5 = pd.DataFrame(common_words, columns = ['desc' , 'count'])\n",
    "df5.groupby('desc').sum()['count'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "desc\n",
       "pike place market               85\n",
       "tacoma international airport    21\n",
       "seattle tacoma international    21\n",
       "free wi fi                      19\n",
       "washington state convention     17\n",
       "seattle art museum              16\n",
       "place market seattle            16\n",
       "state convention center         15\n",
       "high speed internet             14\n",
       "space needle pike               12\n",
       "needle pike place               11\n",
       "south lake union                11\n",
       "sea tac airport                 10\n",
       "downtown seattle hotel          10\n",
       "home away home                   9\n",
       "link light rail                  8\n",
       "just minutes away                8\n",
       "heart downtown seattle           8\n",
       "free high speed                  8\n",
       "24 hour fitness                  7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trigrams Frequency Distribution After Removing Stop Words\n",
    "\n",
    "def get_top_n_trigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(3, 3), stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "common_words = get_top_n_trigram(df['desc'], 20)\n",
    "df6 = pd.DataFrame(common_words, columns = ['desc' , 'count'])\n",
    "df6.groupby('desc').sum()['count'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of descriptions: 152 \n",
      "Average word count 156.94736842105263 \n",
      "Minimum word count 16 \n",
      "Maximum word count 494\n"
     ]
    }
   ],
   "source": [
    "df['word_count'] = df['desc'].apply(lambda x: len(str(x).split()))\n",
    "desc_lengths = list(df['word_count'])\n",
    "print(\"Number of descriptions:\",len(desc_lengths),\n",
    "      \"\\nAverage word count\", np.average(desc_lengths),\n",
    "      \"\\nMinimum word count\", min(desc_lengths),\n",
    "      \"\\nMaximum word count\", max(desc_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      184\n",
       "1      152\n",
       "2      147\n",
       "3      150\n",
       "4      151\n",
       "5      136\n",
       "6       70\n",
       "7      117\n",
       "8      106\n",
       "9      118\n",
       "10     105\n",
       "11      80\n",
       "12     133\n",
       "13      50\n",
       "14      80\n",
       "15     155\n",
       "16     140\n",
       "17     163\n",
       "18     100\n",
       "19     260\n",
       "20     163\n",
       "21      39\n",
       "22     171\n",
       "23     134\n",
       "24     168\n",
       "25     199\n",
       "26     161\n",
       "27     173\n",
       "28     220\n",
       "29     169\n",
       "      ... \n",
       "122    144\n",
       "123     38\n",
       "124    129\n",
       "125    157\n",
       "126    213\n",
       "127    227\n",
       "128    166\n",
       "129    116\n",
       "130    160\n",
       "131    285\n",
       "132    143\n",
       "133    459\n",
       "134    244\n",
       "135     73\n",
       "136    274\n",
       "137    126\n",
       "138    143\n",
       "139    192\n",
       "140    265\n",
       "141    494\n",
       "142    225\n",
       "143     53\n",
       "144     36\n",
       "145     16\n",
       "146    178\n",
       "147    198\n",
       "148     98\n",
       "149    143\n",
       "150     57\n",
       "151    250\n",
       "Name: word_count, Length: 152, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mragu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text\n",
    "    \n",
    "df['desc_clean'] = df['desc'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling\n",
    "\n",
    "df.set_index('name', inplace = True)\n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(df['desc_clean'])\n",
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "indices = pd.Series(df.index)\n",
    "\n",
    "def recommendations(name, cosine_similarities = cosine_similarities):\n",
    "    \n",
    "    recommended_hotels = []\n",
    "    \n",
    "    # gettin the index of the hotel that matches the name\n",
    "    idx = indices[indices == name].index[0]\n",
    "\n",
    "    # creating a Series with the similarity scores in descending order\n",
    "    score_series = pd.Series(cosine_similarities[idx]).sort_values(ascending = False)\n",
    "\n",
    "    # getting the indexes of the 10 most similar hotels except itself\n",
    "    top_10_indexes = list(score_series.iloc[1:11].index)\n",
    "    \n",
    "    # populating the list with the names of the top 10 matching hotels\n",
    "    for i in top_10_indexes:\n",
    "        recommended_hotels.append(list(df.index)[i])\n",
    "        \n",
    "    return recommended_hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Embassy Suites by Hilton Seattle Tacoma International Airport',\n",
       " 'DoubleTree by Hilton Hotel Seattle Airport',\n",
       " 'Seattle Airport Marriott',\n",
       " 'Motel 6 Seattle Sea-Tac Airport South',\n",
       " 'Econo Lodge SeaTac Airport North',\n",
       " 'Four Points by Sheraton Downtown Seattle Center',\n",
       " 'Knights Inn Tukwila',\n",
       " 'Econo Lodge Renton-Bellevue',\n",
       " 'Hampton Inn Seattle/Southcenter',\n",
       " 'Radisson Hotel Seattle Airport']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations('Hilton Seattle Airport & Conference Center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
